{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Data Cube Integration & Slicing\n",
    "\n",
    "This script aggregates the cleaned building-data-genome-project-2 data into a data-cube-frame. The cube is then sliced into three cuboids of the 2D lattice, namely {time, site}, {time, attribute} and {attribute, site}.\n",
    "\n",
    "![3DCube](../figures/3DCube.png)\n",
    "\n",
    "The cuboids are thereafter saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Parameter Selection\n",
    "meter_data = [\"electricity\", \"hotwater\", \"chilledwater\"]\n",
    "weather_cols = [\"airTemperature\", \"seaLvlPressure\"]\n",
    "columns_considered = meter_data + weather_cols\n",
    "\n",
    "# Path & url definition\n",
    "url_root = 'https://media.githubusercontent.com/media/buds-lab/building-data-genome-project-2/master/data/'\n",
    "url_path_meta = \"metadata/\"\n",
    "url_path_weather = \"weather/\"\n",
    "\n",
    "path_meters = \"..\\\\data\\\\cleaned\\\\\"\n",
    "path_data_out = \"..\\\\data\\\\cube\\\\\"\n",
    "\n",
    "meter_files = [path_meters + meter+ \".csv\" for meter in meter_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cube manipulation Function\n",
    "\n",
    "To integrate the building-cube to a dataframe, we structure the meter data to multicolumn dataframes using {meter, building_id} as column keys.\n",
    "The cube integration and manipulation functions are gathered below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_upperlevel_column(df, upperlevel_column_name):\n",
    "    \"\"\"\"A function to define an upper level column over a dataframe.\"\"\"\n",
    "    lowerlevel_column_name = df.columns\n",
    "    tuple_column = []\n",
    "    for i in lowerlevel_column_name:\n",
    "        tuple_column.append((upperlevel_column_name, i))\n",
    "    df.columns = pd.MultiIndex.from_tuples(tuple_column)\n",
    "    return df\n",
    "\n",
    "def intersection(lst1, lst2):\n",
    "    return list(set(lst1) & set(lst2))\n",
    "\n",
    "def union(list1, list2):\n",
    "    return list(set().union(list1, list2))\n",
    "\n",
    "def mergeAll(meter_df, weather_df, metadata_df, intersect_fct=intersection):\n",
    "    \"\"\"\"A function to merge meta, weather and meter data together.\n",
    "    The interstect_fct defines wether merging is done using union or intersection ensembles.\"\"\"\n",
    "\n",
    "    # Extract upper level column (meter_type) information\n",
    "    meter_type_list = []\n",
    "    for meter_type, blg_id in meter_df.columns.values:\n",
    "        meter_type_list.append(meter_type)\n",
    "    meter_type_list = list(set(meter_type_list))\n",
    "\n",
    "    #  Identify only unique building ID within the meters considered\n",
    "    blg_dict = dict()\n",
    "    i = True\n",
    "    for meter in meter_type_list:\n",
    "        blg_dict[meter] = []\n",
    "        for blg_id in meter_df[meter].columns.values:\n",
    "            blg_dict[meter].append(blg_id)\n",
    "        if i:\n",
    "            blg_list_intersect = blg_dict[meter]\n",
    "            i = False\n",
    "        else:\n",
    "            blg_list_intersect = intersect_fct(blg_dict[meter], blg_list_intersect)\n",
    "\n",
    "    # Filters metadata with only current meter info & unique building intersection ids\n",
    "    site_list = []\n",
    "    for metername in meter_type_list:\n",
    "        df_meta = metadata_df.loc[np.logical_and(metadata_df[metername] == \"Yes\", metadata_df[\"building_id\"].isin(blg_list_intersect)),\n",
    "                                  [\"building_id\", \"site_id\"]].copy()\n",
    "        site_list.extend(list(df_meta.site_id.unique()))\n",
    "    site_list_unique = list(set(site_list))\n",
    "\n",
    "    # Filters weather with only current sites\n",
    "    df_weather = weather_df.loc[weather_df[\"site_id\"].isin(site_list_unique) == True,].copy()\n",
    "    # Converts timestamp to datetime object\n",
    "    df_weather[\"timestamp\"] = pd.to_datetime(df_weather[\"timestamp\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    dfs = []\n",
    "    for i in meter_type_list:\n",
    "        # Select only intersecting information within a set of buildings\n",
    "        df = pd.melt(meter_df[i][intersection(blg_dict[i], blg_list_intersect)].reset_index(),\n",
    "                      id_vars=\"timestamp\",\n",
    "                      var_name=\"building_id\",\n",
    "                      value_name=i)\n",
    "        df.set_index([\"building_id\", \"timestamp\"], inplace=True)\n",
    "        dfs.append(df)  # append to list\n",
    "    meter_df = pd.concat(dfs, axis=1)\n",
    "    del (dfs, df)\n",
    "\n",
    "    # Merge\n",
    "    meter_df = pd.merge(meter_df.reset_index(), df_meta, how=\"left\", on=\"building_id\").merge(\n",
    "        df_weather, how=\"left\", on=[\"timestamp\", \"site_id\"])\n",
    "    return meter_df\n",
    "\n",
    "def multicol_2ndColumnSelection(df_multicol, allcol1, col2):\n",
    "    \"\"\"\"Function to select data from a multi-column dataframe based on the 2nd column value.\n",
    "    From a defined 2nd-level column of interest - col2,\n",
    "     the function loops over the dataframe from all the values interest from the 1st-level column - allcol1\"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    for i in allcol1:\n",
    "        df[i] = df_multicol[i, col2].copy()\n",
    "    return df\n",
    "\n",
    "def multi2singlecol_1stCol(df_in):\n",
    "    \"\"\"\"Function to transform a 2 column dataframe to a single one, while appending the 2nd column information\n",
    "    to a new attribute.\"\"\"\n",
    "    # Extract upper level column meter_type information\n",
    "    meter_type_list = []\n",
    "    for meter_type, blg_id in df_in.columns.values:\n",
    "        meter_type_list.append(meter_type)\n",
    "    meter_type_list = list(set(meter_type_list))\n",
    "\n",
    "    dfs = []\n",
    "    for i in meter_type_list:\n",
    "        df1 = pd.melt(df_in[i].reset_index(),\n",
    "                      id_vars=df_in.index.name,\n",
    "                      var_name=\"building_id\",\n",
    "                      value_name=i)\n",
    "        df1.set_index([\"building_id\", df_in.index.name], inplace=True)\n",
    "        dfs.append(df1)  # append to list\n",
    "    meter_df = pd.concat(dfs, axis=1)\n",
    "    meter_df = meter_df.reset_index().set_index([df_in.index.name], drop=True)\n",
    "    return meter_df\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"\"Function to reduce the memory usage of a dataframe.\n",
    "    Source: https://www.kaggle.com/caesarlupum/ashrae-start-here-a-gentle-introduction\"\"\"\n",
    "\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather\n",
    "weather = pd.read_csv(url_root + url_path_weather + \"weather.csv\", usecols=([\"timestamp\",\"site_id\"]+weather_cols))\n",
    "\n",
    "# Meta data\n",
    "meta = pd.read_csv(url_root + url_path_meta + \"metadata.csv\", usecols=[\"building_id\",\"site_id\"]+meter_data,)\n",
    "\n",
    "# Meter data\n",
    "dfs = [] # empty list of the dataframes to create\n",
    "for f in meter_files:\n",
    "    meter_type = f.split(\"\\\\\")[3].split(\".\")[0]\n",
    "    meter = pd.read_csv(f, index_col=\"timestamp\") # load the dataset\n",
    "    # Define multicolumn Dataframe\n",
    "    meter = set_upperlevel_column(meter, meter_type)\n",
    "    dfs.append(meter)  # append to list\n",
    "# Concatenate all meters\n",
    "df_meter = pd.concat(dfs, axis=1)\n",
    "del(dfs, meter, f, meter_files)\n",
    "# Format index to datetime object\n",
    "df_meter.index = pd.to_datetime(df_meter.index, format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mem. usage decreased to 1212.18 Mb (36.1% reduction)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                            electricity                         \\\n",
       "building_id         Bear_assembly_Angel Bear_assembly_Beatrice   \n",
       "timestamp                                                        \n",
       "2016-01-01 00:00:00             225.750               9.562500   \n",
       "2016-01-01 01:00:00             225.750               9.562500   \n",
       "2016-01-01 02:00:00             225.750               9.562500   \n",
       "2016-01-01 03:00:00             222.375               9.812500   \n",
       "2016-01-01 04:00:00             227.375               9.546875   \n",
       "\n",
       "                                                              \\\n",
       "building_id         Bear_assembly_Danial Bear_assembly_Diana   \n",
       "timestamp                                                      \n",
       "2016-01-01 00:00:00                  NaN                 NaN   \n",
       "2016-01-01 01:00:00                  NaN                 NaN   \n",
       "2016-01-01 02:00:00                  NaN                 NaN   \n",
       "2016-01-01 03:00:00                  NaN                 NaN   \n",
       "2016-01-01 04:00:00                  NaN                 NaN   \n",
       "\n",
       "                                                             \\\n",
       "building_id         Bear_assembly_Genia Bear_assembly_Harry   \n",
       "timestamp                                                     \n",
       "2016-01-01 00:00:00             183.125                 NaN   \n",
       "2016-01-01 01:00:00             183.125                 NaN   \n",
       "2016-01-01 02:00:00             183.125                 NaN   \n",
       "2016-01-01 03:00:00             185.250                 NaN   \n",
       "2016-01-01 04:00:00             185.500                 NaN   \n",
       "\n",
       "                                                                              \\\n",
       "building_id         Bear_assembly_Jose Bear_assembly_Roxy Bear_assembly_Ruby   \n",
       "timestamp                                                                      \n",
       "2016-01-01 00:00:00             149.75             9.8125            51.6250   \n",
       "2016-01-01 01:00:00             149.75             9.8125            51.6250   \n",
       "2016-01-01 02:00:00             149.75             9.8125            51.6250   \n",
       "2016-01-01 03:00:00             152.25             9.8750            51.6250   \n",
       "2016-01-01 04:00:00             151.25             9.9375            51.3125   \n",
       "\n",
       "                                            ...      seaLvlPressure  \\\n",
       "building_id         Bear_education_Alfredo  ... Wolf_office_Emanuel   \n",
       "timestamp                                   ...                       \n",
       "2016-01-01 00:00:00               0.100647  ...                 NaN   \n",
       "2016-01-01 01:00:00               0.100647  ...                 NaN   \n",
       "2016-01-01 02:00:00               0.100647  ...                 NaN   \n",
       "2016-01-01 03:00:00               0.104370  ...                 NaN   \n",
       "2016-01-01 04:00:00               0.106262  ...                 NaN   \n",
       "\n",
       "                                                                            \\\n",
       "building_id         Wolf_office_Haydee Wolf_office_Joana Wolf_office_Nadia   \n",
       "timestamp                                                                    \n",
       "2016-01-01 00:00:00                NaN               NaN               NaN   \n",
       "2016-01-01 01:00:00                NaN               NaN               NaN   \n",
       "2016-01-01 02:00:00                NaN               NaN               NaN   \n",
       "2016-01-01 03:00:00                NaN               NaN               NaN   \n",
       "2016-01-01 04:00:00                NaN               NaN               NaN   \n",
       "\n",
       "                                                            \\\n",
       "building_id         Wolf_office_Rochelle Wolf_public_Norma   \n",
       "timestamp                                                    \n",
       "2016-01-01 00:00:00                  NaN               NaN   \n",
       "2016-01-01 01:00:00                  NaN               NaN   \n",
       "2016-01-01 02:00:00                  NaN               NaN   \n",
       "2016-01-01 03:00:00                  NaN               NaN   \n",
       "2016-01-01 04:00:00                  NaN               NaN   \n",
       "\n",
       "                                                               \\\n",
       "building_id         Wolf_retail_Harriett Wolf_retail_Marcella   \n",
       "timestamp                                                       \n",
       "2016-01-01 00:00:00                  NaN                  NaN   \n",
       "2016-01-01 01:00:00                  NaN                  NaN   \n",
       "2016-01-01 02:00:00                  NaN                  NaN   \n",
       "2016-01-01 03:00:00                  NaN                  NaN   \n",
       "2016-01-01 04:00:00                  NaN                  NaN   \n",
       "\n",
       "                                                             \n",
       "building_id         Wolf_retail_Toshia Wolf_science_Alfreda  \n",
       "timestamp                                                    \n",
       "2016-01-01 00:00:00                NaN                  NaN  \n",
       "2016-01-01 01:00:00                NaN                  NaN  \n",
       "2016-01-01 02:00:00                NaN                  NaN  \n",
       "2016-01-01 03:00:00                NaN                  NaN  \n",
       "2016-01-01 04:00:00                NaN                  NaN  \n",
       "\n",
       "[5 rows x 7875 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"10\" halign=\"left\">electricity</th>\n      <th>...</th>\n      <th colspan=\"10\" halign=\"left\">seaLvlPressure</th>\n    </tr>\n    <tr>\n      <th>building_id</th>\n      <th>Bear_assembly_Angel</th>\n      <th>Bear_assembly_Beatrice</th>\n      <th>Bear_assembly_Danial</th>\n      <th>Bear_assembly_Diana</th>\n      <th>Bear_assembly_Genia</th>\n      <th>Bear_assembly_Harry</th>\n      <th>Bear_assembly_Jose</th>\n      <th>Bear_assembly_Roxy</th>\n      <th>Bear_assembly_Ruby</th>\n      <th>Bear_education_Alfredo</th>\n      <th>...</th>\n      <th>Wolf_office_Emanuel</th>\n      <th>Wolf_office_Haydee</th>\n      <th>Wolf_office_Joana</th>\n      <th>Wolf_office_Nadia</th>\n      <th>Wolf_office_Rochelle</th>\n      <th>Wolf_public_Norma</th>\n      <th>Wolf_retail_Harriett</th>\n      <th>Wolf_retail_Marcella</th>\n      <th>Wolf_retail_Toshia</th>\n      <th>Wolf_science_Alfreda</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2016-01-01 00:00:00</th>\n      <td>225.750</td>\n      <td>9.562500</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>183.125</td>\n      <td>NaN</td>\n      <td>149.75</td>\n      <td>9.8125</td>\n      <td>51.6250</td>\n      <td>0.100647</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2016-01-01 01:00:00</th>\n      <td>225.750</td>\n      <td>9.562500</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>183.125</td>\n      <td>NaN</td>\n      <td>149.75</td>\n      <td>9.8125</td>\n      <td>51.6250</td>\n      <td>0.100647</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2016-01-01 02:00:00</th>\n      <td>225.750</td>\n      <td>9.562500</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>183.125</td>\n      <td>NaN</td>\n      <td>149.75</td>\n      <td>9.8125</td>\n      <td>51.6250</td>\n      <td>0.100647</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2016-01-01 03:00:00</th>\n      <td>222.375</td>\n      <td>9.812500</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>185.250</td>\n      <td>NaN</td>\n      <td>152.25</td>\n      <td>9.8750</td>\n      <td>51.6250</td>\n      <td>0.104370</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2016-01-01 04:00:00</th>\n      <td>227.375</td>\n      <td>9.546875</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>185.500</td>\n      <td>NaN</td>\n      <td>151.25</td>\n      <td>9.9375</td>\n      <td>51.3125</td>\n      <td>0.106262</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 7875 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Merging weather, meter and meta-data \n",
    "df_all = mergeAll(df_meter, weather, meta, intersect_fct=union)\n",
    "# Reduce memory usage\n",
    "df_all = reduce_mem_usage(df_all, verbose=True)\n",
    "\n",
    "# Unmelt for multicolumn frame {attribute_X, building_id}\n",
    "df_cube = df_all.pivot(index=\"timestamp\", columns=\"building_id\", values=columns_considered)\n",
    "df_cube.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cube slicing\n",
    "## A - Building Benchmarking\n",
    "Cuboid {time, site} selection, shows an inter-building analytical frame, typically relevant for cross building benchmarking from top-down approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fix attribute\n",
    "attribute = columns_considered[0]\n",
    "\n",
    "# Cuboid selection\n",
    "df_cubA = df_cube[attribute]\n",
    "#df_cubA.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Save cube slice\n",
    "df_cubA.to_csv(path_data_out+\"cuboid_A_\"+attribute+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B - In-site view\n",
    "Cuboid {time, attribute} selection covers the intra-building frame, common to bottom-up approaches. It serves for within-site exploration on how a given building operates across time and building-specific attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix building identification\n",
    "blg_id = \"Fox_education_Melinda\"\n",
    "\n",
    "# Cuboid selection\n",
    "df_cubB = multicol_2ndColumnSelection(df_cube, columns_considered, blg_id)\n",
    "#df_cubB.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Save cube slice\n",
    "df_cubB.to_csv(path_data_out+\"cuboid_B_\"+blg_id+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C - Cross building/attribute slice\n",
    "The {site, attribute} cuboid allows exploration of cross-building/attributes combined analysis within a fixed time slice of interested for temporal drill-in analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Per timerange insight\n",
    "timestamp = \"2016-06-07\"\n",
    "start_date = timestamp+\" 00:00:00\"\n",
    "end_date = timestamp+\" 23:00:00\"\n",
    "timerange_considered = (df_cube.index >= start_date) & (df_cube.index <= end_date)\n",
    "\n",
    "# Cuboid selection\n",
    "df_cubC = df_cube.loc[timerange_considered]\n",
    "#df_cubC.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Save cube slice\n",
    "df_cubC.to_csv(path_data_out+\"cuboid_C_\"+timestamp+'.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}